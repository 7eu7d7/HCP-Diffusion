# base_state*base_model_alpha + (lora_state[i]*lora_scale[i]*lora_alpha[i]) + (part_state[k]*part_alpha[k])

exp_dir: '2023-04-03-10-10-36'
alpha: 0.7

group1:
  type: 'unet'
  base_model_alpha: 1.0 # base model weight to merge with lora or part
  lora:
    - path: 'exps/${....exp_dir}/ckpts/unet-600.ckpt'
      alpha: ${....alpha}
      layers: 'all'
      mask: [0.5, 1]
    - path: 'exps/${....exp_dir}/ckpts/unet-neg-600.ckpt'
      alpha: 0.55
      layers: 'all'
      mask: [0, 0.5]
  part: null

group2:
  type: 'TE'
  base_model_alpha: 1.0 # base model weight to merge with lora or part
  lora:
    - path: 'exps/${....exp_dir}/ckpts/text_encoder-600.ckpt'
      alpha: ${....alpha}
      layers: 'all'
      mask: [0.5, 1]
    - path: 'exps/${....exp_dir}/ckpts/text_encoder-neg-600.ckpt'
      alpha: 0.55
      layers: 'all'
      mask: [0, 0.5]
  part: null